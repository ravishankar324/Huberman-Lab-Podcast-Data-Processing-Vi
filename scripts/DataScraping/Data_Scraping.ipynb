{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import os\n",
    "import boto3\n",
    "import io\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retreiving the API keys and AWS Credentials from the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the API key and channel ID\n",
    "api_key = os.getenv(\"YOUTUBE_API_KEY\").strip()\n",
    "channel_id = os.getenv(\"CHANNEL_ID\").strip()\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "aws_region = os.getenv(\"AWS_REGION\")\n",
    "\n",
    "#Initialize the S3 client\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=aws_region)\n",
    "\n",
    "# Initialize YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "print(aws_access_key_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch Channel Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def channel_details(youtube, channel_id):\n",
    "    nextPageToken = None\n",
    "    while True: \n",
    "            # Fetch video ids from the specified channel using pagination\n",
    "        response_1 = youtube.channels().list(\n",
    "                id=channel_id,\n",
    "                part=\"snippet, contentDetails, statistics\",\n",
    "                pageToken=nextPageToken\n",
    "\n",
    "            ).execute()\n",
    "\n",
    "        nextPageToken = response_1.get('nextPageToken')\n",
    "\n",
    "        if not nextPageToken:\n",
    "            break\n",
    "\n",
    "    return response_1\n",
    "channel_details = channel_details(youtube, channel_id)\n",
    "channel_details_df = pd.DataFrame(channel_details['items'])\n",
    "bucket_name = 'andrew-huberman-podcast-analytics'\n",
    "s3_key = 'channeldetails/channeldetails.csv'\n",
    "\n",
    "# Convert DataFrame to CSV in memory\n",
    "csv_buffer = io.StringIO()\n",
    "channel_details_df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "s3_client.put_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=s3_key,\n",
    "    Body=csv_buffer.getvalue()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the video ids details from the channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videoids(youtube, channel_id):\n",
    "    nextPageToken = None\n",
    "    videoids = []\n",
    "    \n",
    "    while True: \n",
    "            # Fetch video ids from the specified channel using pagination\n",
    "        response_1 = youtube.search().list(\n",
    "                channelId=channel_id,\n",
    "                type = 'video',\n",
    "                part=\"id,snippet\",\n",
    "                maxResults = 50,\n",
    "                pageToken=nextPageToken\n",
    "\n",
    "            ).execute()\n",
    "\n",
    "        nextPageToken = response_1.get('nextPageToken')\n",
    "\n",
    "        for i in response_1['items']:\n",
    "            videoids.append(i['id']['videoId'])\n",
    "            \n",
    "\n",
    "        if not nextPageToken:\n",
    "            break\n",
    "\n",
    "    return videoids\n",
    "\n",
    "# Get the total number of videos\n",
    "videoids = get_videoids(youtube, channel_id)\n",
    "# Create a DataFrame from the video IDs and save it to a CSV file with an index, overwriting the existing file\n",
    "videoids_df = pd.DataFrame(videoids, columns=['video_id'])\n",
    "bucket_name = 'andrew-huberman-podcast-analytics'\n",
    "s3_key = 'videoids/videoids.csv'\n",
    "\n",
    "# Convert DataFrame to CSV in memory\n",
    "csv_buffer_videoids = io.StringIO()\n",
    "videoids_df.to_csv(csv_buffer_videoids, index=True)\n",
    "\n",
    "s3_client.put_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=s3_key,\n",
    "    Body=csv_buffer_videoids.getvalue()\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch video details From using video ids of channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(youtube, video_ids):\n",
    "    all_videos = []\n",
    "    # Process in chunks of 50 IDs\n",
    "    for chunk in chunk_video_ids(video_ids, 50):\n",
    "        response = youtube.videos().list(\n",
    "            id=','.join(chunk),\n",
    "            part=\"snippet,contentDetails,statistics\"\n",
    "        ).execute()\n",
    "        all_videos.extend(response.get('items', []))\n",
    "\n",
    "    return all_videos\n",
    "\n",
    "# Helper function to break video IDs into 50 \n",
    "def chunk_video_ids(video_ids, chunk_size=50):\n",
    "    for i in range(0, len(video_ids), chunk_size):\n",
    "        yield video_ids[i:i + chunk_size]\n",
    "\n",
    "  # Example IDs\n",
    "videos = get_videos(youtube, videoids)\n",
    "print(len(videos))\n",
    "videos_df = pd.DataFrame(videos)\n",
    "\n",
    "bucket_name = 'andrew-huberman-podcast-analytics'\n",
    "s3_key = 'videos/videos.csv'\n",
    "\n",
    "# Convert DataFrame to CSV in memory\n",
    "csv_buffer_videos = io.StringIO()\n",
    "videos_df.to_csv(csv_buffer_videos, index=False)\n",
    "\n",
    "s3_client.put_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=s3_key,\n",
    "    Body=csv_buffer_videos.getvalue()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fetch comments for all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_comments(youtube, video_id):\n",
    "    # Fetch comments from the specified video\n",
    "    PageToken = None\n",
    "    comments_list = []\n",
    "    while True:\n",
    "        response = youtube.commentThreads().list(\n",
    "            part=\"snippet,replies\",\n",
    "            videoId=video_id,\n",
    "            maxResults=100,\n",
    "            pageToken=PageToken\n",
    "        ).execute()\n",
    "\n",
    "        comments_list.extend(response['items'])\n",
    "\n",
    "        PageToken = response.get('nextPageToken')\n",
    "\n",
    "        if not PageToken:\n",
    "            break\n",
    "    return comments_list\n",
    "\n",
    "df = pd.read_csv('videoids/videoids.csv')\n",
    "\n",
    "bucket_name = 'andrew-huberman-podcast-analytics'\n",
    "for i in range(200, 280):\n",
    "    video_id = df.loc[i]['video_id']\n",
    "    comment_details = get_all_comments(youtube, video_id)\n",
    "    comments_df = pd.DataFrame(comment_details)\n",
    "\n",
    "    # Convert to parquet format in memory\n",
    "    parquet_buffer = io.BytesIO()\n",
    "    comments_df.to_parquet(parquet_buffer)\n",
    "\n",
    "    # Upload to S3\n",
    "    s3_key = f'comments/{video_id}_{i}.parquet'\n",
    "    s3_client.put_object(\n",
    "        Bucket=bucket_name,\n",
    "        Key=s3_key,\n",
    "        Body=parquet_buffer.getvalue(),\n",
    ")\n",
    "    print(f'completed file {i} and uploaded to S3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
